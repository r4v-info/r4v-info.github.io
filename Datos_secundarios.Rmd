---
title: "Datos secundarios"
---

```{r options_communes, include=FALSE}
source("options_communes.R")
```


<div class="important">
- Para evitar la duplicación de evaluaciones de necesidades, se recomienda realizar una revisión exhaustiva de datos secundarios y del registro de evaluaciones al comienzo del proceso de evaluación, para identificar vacíos y necesidades de información.
- Compartir, almacenar y promover el uso de datos e informes a través de la plataforma regional y plataformas nacionales y otro tipo de medios disponibles como HumanitarianResponse, ReliefWeb, etc.

</div>



Antes de comenzar a recolectar datos en terreno es fundamental hacer una revisión de los datos ya existentes para evitar la duplicación de esfuerzos y ahorrar tiempo y recursos.

Los datos secundarios se definen como fuentes de información que han sido recolectadas por otros actores, con propósitos distintos a los de la evaluación que se quiere llevar a cabo.

Basándose en el plan de análisis de datos, la revisión de datos secundaria establece la información conocida y no conocida sobre una situación concreta y su impacto, incluyendo detalles del volumen y el estado de las poblaciones afectadas y la severidad de sus condiciones humanitarias. La revisión involucra la recolección y análisis de información previa a la crisis y específica de la crisis, estadísticas, demografías y otros datos relevantes.

Las principales tareas que hay que llevar a cabo durante una revisión de datos secundarios son detalladas a continuación:

## Paso 1. Localizar información relevante

Localizar informes, conjuntos de datos y productos con análisis de información precrisis y de la crisis. Un registro de evaluaciones es un buen punto de partida, ya que proporciona un listado de los informes, estudios, evaluaciones de necesidades etc. que ya han sido realizados por otros actores. En este [enlace](https://r4v.info/es/documents/details/71288) puede consultar el registro de evaluaciones del Grupo Inter agencial sobre Flujos Migratorios Mixtos en Colombia. Por otra parte, se [puede consultar este documento](http://pim.guide/wp-content/uploads/2018/05/Framework-for-Data-Sharing-in-Practice.pdf), el cual provee una guía para establecer un sistema para compartir información.



Una vez se han recolectado las fuentes de datos, se deben almacenar de forma que se puedan encontrar fácilmente. Para ello, se recomienda utilizar un formato estandarizado para nombrar archivos, que incluya información sobre el autor, el título del informe, la fecha del informe y cómo se deben tratar los datos según su confidencialidad, por ejemplo: 20181104\_GIFMM\_EvaluaciónNecesidades\_Protegido.

## Paso 2. Organizar los datos

El siguiente paso consiste en encontrar y organizar el contenido más relevante de toda la información recopilada. Para evitar perderse entre grandes cantidades de información, es importante utilizar una forma sistematizada de etiquetado y almacenamiento de la información.

Las categorías más comunes de etiquetado incluyen:

- **Fuente de información** : Fecha, autor, técnica de recolección de datos.
- **Alcance** : áreas geográficas, sectores y grupos afectados.
- **Temática** : usar una estructura preexistente de etiquetado, basada en el plan de análisis de datos. Esto es un requerimiento esencial si más de una analista está trabajando en el etiquetado.
- **Confidencialidad** : proporcionar detalles sobre si los datos son: abiertos, restringidos, protegidos o confidenciales.
- **Confiabilidad de la fuente** : definir si las fuentes son confiables, no confiables, etc. Existen varias técnicas para definir la confiabilidad de los datos, puede encontrar un ejemplo en este [enlace](https://en.wikipedia.org/wiki/Intelligence_source_and_information_reliability).


Para el etiquetado y almacenamiento de los datos usualmente se utilizan hojas de cálculo de Excel. Sin embargo, han surgido plataformas más fáciles de utilizar en los últimos años.

[**DEEP**](https://beta.thedeep.io/) es un software gratuito de código abierto para la revisión colaborativa de datos secundarios y gestión de datos no estructurados. Los usuarios pueden cargar una variedad de fuentes (artículos de noticias, PDF, documentos de Word, etc.) y etiquetarlas usando marcos analíticos personalizados. La información catalogada se puede exportar a Excel o Word junto con la referenciación para su posterior análisis.

DEEP ha sido utilizado para la realización de revisiones de datos secundarios para la planeación del RMRP 2020 y actualmente contiene proyectos para los siguientes países: Argentina, Aruba, Brasil, Colombia, Chile, Ecuador, Perú, Panamá y Uruguay. El marco de análisis utilizado para guiar el etiquetado de los datos corresponde al marco analítico regional en la sección 4.3.1.

## Paso 3. Validación de la información

Después de que se haya sistematizado toda la información, se selecciona la información más útil y confiable utilizando los siguientes criterios:

- Relevancia: ¿Cubre el área geográfica, temática, grupo de población y período de tiempo de interés?
- Nivel de detalle: ¿proporciona el nivel de detalle requerido?
- Comparabilidad: ¿permite la comparación con otros conjuntos de datos importantes para su revisión?
- Confiabilidad: Al observar la fuente de la información y el método utilizado para recopilar la información, ¿es confiable la información? Hay que tener cuidado con la inclusión de datos que provienen de informes sin una descripción detallada de la metodología y el cuestionario.


## Paso 4. Consolidación de la información

Ahora que toda la información relevante está etiquetada, estructurada y almacenada, es hora de sintetizar los datos cuantitativos y cualitativos. Se deberá consolidar la información resumiendo los hallazgos por área geográfica, grupos de población de interés y / o diferentes temáticas. Se debe comenzar describiendo los conjuntos de datos más grandes y confiables, la situación general, y a continuación, se identificará la información más detallada.

Posteriormente, proporcionar comparaciones utilizando las categorías de análisis predefinidas. ¿Cómo difieren los resultados, por ejemplo, entre distintas localizaciones, grupos de población o en el tiempo? Se pueden utilizar estándares comunes de emergencia (por ejemplo, estándares Esfera, Manual de Emergencia del ACNUR, Estándares WASH) para poner los hallazgos en perspectiva.

En los casos en los que la información sea inconsistente o conflictiva, hay dos opciones, incluir la información más confiable y útil, o incluir toda la información y explicar las posibles razones a las que se debe la diferencia entre los resultados.

## Paso 5. Análisis de la información

Una vez que todos los datos han sido consolidados se deberán analizar, sí es posible en grupos formados por expertos y responsables de tomas de decisión, mediante:

- Explicar las relaciones entre los distintos problemas, observando posibles causas, efectos y factores subyacentes.
- Interpretar los hallazgos priorizando áreas geográficas, grupos poblaciones y necesidades.
- Anticipar lo que podría suceder prediciendo la posible evolución de la crisis.

Finalmente, el plan de análisis de datos puede ser actualizado con la información más relevante y útil, teniendo en cuenta que, en algunas ocasiones, múltiples fuentes de datos deberán ser combinadas.
